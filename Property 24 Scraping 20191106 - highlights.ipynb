{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scrapy and pandas\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import pandas as pd\n",
    "\n",
    "# Initiate empty dictionary with features to extract\n",
    "Features = {\"Price\": [],\n",
    "            \"Bedrooms\": [],\n",
    "            \"Location\": [],\n",
    "            \"Garages\": [],\n",
    "            \"Bathrooms\": [],\n",
    "            \"Erf Size\": [],\n",
    "            \"Floor Size\": []}\n",
    "\n",
    "#Initiate a scrapy Spider\n",
    "class Prop24(scrapy.spiders.Spider):\n",
    "    name = 'Prop24'\n",
    "    \n",
    "#Define website to scrape data from(Currently only for housees in the Western Cape)\n",
    "    def start_requests(self):\n",
    "        urls = ['https://www.property24.com/houses-for-sale/western-cape/9']\n",
    "            \n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "#Extract various features from website             \n",
    "    def parse(self, response):\n",
    "        \n",
    "        number = len(response.xpath('//span[@class=\"p24_content\"]')) #Obtain the amount of housing ads per page\n",
    "         \n",
    "        for i in range(number): #Initiate loop to run through all adds and extract data\n",
    "            \n",
    "            #Extract pricing data\n",
    "            xpath_price = '(//span[@class=\"p24_content\"])[{0}]/span[@itemprop=\"offers\"]/span[@class=\"p24_price\"]/@content'.format(i)\n",
    "            price = response.xpath(xpath_price).extract()\n",
    "            \n",
    "            #Extract amount of bedrooms\n",
    "            xpath_bedrooms = '(//span[@class=\"p24_content\"])[{0}]/span[@class=\"p24_icons\"]/span[contains(@title, \"Bedrooms\")]/span/text()'.format(i)\n",
    "            bedrooms = response.xpath(xpath_bedrooms).extract()\n",
    "          \n",
    "            #Extract location\n",
    "            xpath_location = '(//span[@class=\"p24_content\"])[{0}]/span[@itemprop=\"offers\"]/span[contains(@class,\"p24_location\")]/text()'.format(i)\n",
    "            location = response.xpath(xpath_location).extract()\n",
    "  \n",
    "            #Extract amount of bathrooms\n",
    "            xpath_bathrooms = '(//span[@class=\"p24_content\"])[{0}]/span[@class=\"p24_icons\"]/span[contains(@title, \"Bathrooms\")]/span/text()'.format(i)\n",
    "            bathrooms = response.xpath(xpath_bathrooms).extract()\n",
    "\n",
    "            #Extract amount of garages\n",
    "            xpath_garages = '(//span[@class=\"p24_content\"])[{0}]/span[@class=\"p24_icons\"]/span[contains(@title, \"Parking Spaces\")]/span/text()'.format(i)\n",
    "            garages = response.xpath(xpath_garages).extract()        \n",
    "          \n",
    "            #Extract erf size\n",
    "            xpath_erf_size = '(//span[@class=\"p24_content\"])[{0}]/span[@class=\"p24_icons\"]/span[contains(@title, \"Erf Size\")]/span/text()'.format(i)\n",
    "            erf_size = response.xpath(xpath_erf_size).extract()       \n",
    "\n",
    "            #Extract house floor size\n",
    "            xpath_floor_size = '(//span[@class=\"p24_content\"])[{0}]/span[@class=\"p24_icons\"]/span[contains(@title, \"Floor Size\")]/span/text()'.format(i)\n",
    "            floor_size = response.xpath(xpath_floor_size).extract()              \n",
    "            \n",
    "            #Check if item exists and append the dictionary with the appropriate feature.\n",
    "            if len(price)==0: \n",
    "                Features['Price'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                Features['Price'].append(price[0])\n",
    "                \n",
    "            if len(bedrooms)==0:\n",
    "                \n",
    "                Features['Bedrooms'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                Features['Bedrooms'].append(bedrooms[0])\n",
    "                \n",
    "            if len(location)==0:\n",
    "                \n",
    "                Features['Location'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                 Features['Location'].append(location[0])\n",
    "\n",
    "            if len(bathrooms)==0:\n",
    "                \n",
    "                Features['Bathrooms'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                 Features['Bathrooms'].append(bathrooms[0])     \n",
    "                    \n",
    "                    \n",
    "            if len(garages)==0:\n",
    "                \n",
    "                Features['Garages'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                 Features['Garages'].append(garages[0])  \n",
    "                    \n",
    "            if len(erf_size)==0:\n",
    "                \n",
    "                Features['Erf Size'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                 Features['Erf Size'].append(erf_size[0])                                          \n",
    " \n",
    "            if len(floor_size)==0:\n",
    "                \n",
    "                Features['Floor Size'].append('0')\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                 Features['Floor Size'].append(floor_size[0]) \n",
    "                    \n",
    "        #Extract the link to the next page\n",
    "        next_pages = response.xpath('//ul[contains(@class,\"pagination\")]/li/a/@href').extract()\n",
    "        \n",
    "        #Follow the next page and extract until last page is reached.\n",
    "        if next_pages is not None:\n",
    "                \n",
    "            for next_page in next_pages:\n",
    "                yield response.follow(url=next_page, callback=self.parse)\n",
    "            \n",
    "#Start spider process\n",
    "process = CrawlerProcess()\n",
    "process.crawl(Prop24)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store extracted data in a pandas dataframe\n",
    "features_data = pd.DataFrame(Features)\n",
    "\n",
    "#Sort dataframe according to location\n",
    "features_data = features_data.sort_values(['Location'], ascending=True).set_index(['Location'])\n",
    "\n",
    "\n",
    "#Write dataframe to csv file\n",
    "features_data.to_excel('Western_Cape_Housing_Sales.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
